{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Teaching Computational Linguistics with Jupyter\n",
    "\n",
    "Varada Kolhatkar [[ʋəɾəda kɔːlɦəʈkər]](https://en.wikipedia.org/wiki/International_Phonetic_Alphabet)\n",
    "\n",
    "Assistant Professor of Teaching in Computer Science\n",
    "\n",
    "\n",
    "<center>\n",
    "<img src=\"images/WhatisCL.png\" height=\"1000\" width=\"1000\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Slide settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from traitlets.config.manager import BaseJSONConfigManager\n",
    "from pathlib import Path\n",
    "path = Path.home() / \".jupyter\" / \"nbconfig\"\n",
    "cm = BaseJSONConfigManager(config_dir=str(path))\n",
    "tmp = cm.update(\n",
    "        \"rise\",\n",
    "        {\n",
    "            \"theme\": \"sky\",\n",
    "            \"transition\": \"fade\",\n",
    "            \"start_slideshow_at\": \"selected\",            \n",
    "            \"width\": \"100%\",\n",
    "            \"height\": \"100%\",\n",
    "            \"header\": \"\",\n",
    "            \"footer\":\"\",\n",
    "            \"scroll\": True,\n",
    "            \"enable_chalkboard\": True,\n",
    "            \"slideNumber\": True,\n",
    "            \"center\": False,\n",
    "            \"controlsLayout\": \"edges\",\n",
    "            \"slideNumber\": True,\n",
    "            \"hash\": True,\n",
    "        }\n",
    "    )\n",
    "# Documentation on customizing rise: https://rise.readthedocs.io/en/5.1.0/customize.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".rendered_html table, .rendered_html th, .rendered_html tr, .rendered_html td {\n",
       "     font-size: 130%;\n",
       "}\n",
       "\n",
       "body.rise-enabled div.inner_cell>div.input_area {\n",
       "    font-size: 100%;\n",
       "}\n",
       "\n",
       "body.rise-enabled div.output_subarea.output_text.output_result {\n",
       "    font-size: 100%;\n",
       "}\n",
       "body.rise-enabled div.output_subarea.output_text.output_stream.output_stdout {\n",
       "  font-size: 150%;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style>\n",
    ".rendered_html table, .rendered_html th, .rendered_html tr, .rendered_html td {\n",
    "     font-size: 130%;\n",
    "}\n",
    "\n",
    "body.rise-enabled div.inner_cell>div.input_area {\n",
    "    font-size: 100%;\n",
    "}\n",
    "\n",
    "body.rise-enabled div.output_subarea.output_text.output_result {\n",
    "    font-size: 100%;\n",
    "}\n",
    "body.rise-enabled div.output_subarea.output_text.output_stream.output_stdout {\n",
    "  font-size: 150%;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "## import the libraries \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "\n",
    "import IPython\n",
    "from IPython.display import HTML\n",
    "\n",
    "# For text preprocessing\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def display_url(url): \n",
    "    \"\"\"\n",
    "    Given a url, display it as an iframe. \n",
    "    \n",
    "    Arguments: \n",
    "    ----------\n",
    "    url : str\n",
    "        The url to be displayed \n",
    "    \n",
    "    Return:\n",
    "    ----------\n",
    "    None\n",
    "    \"\"\"\n",
    "    display(HTML(\"<iframe src=%s width=1000 height=900 allowfullscreen></iframe>\"%url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Goal \n",
    "\n",
    "- To give you a high-level overview of language models.  \n",
    "- To demonstrate how I use Jupyter with RISE to teach with different modalities.  \n",
    "    - Text\n",
    "    - Mathematical equations with latex\n",
    "    - Images\n",
    "    - **Code**\n",
    "    - **Videos** \n",
    "    - **Interactive websites**\n",
    "- [RISE](https://rise.readthedocs.io/en/5.1.0/index.html)\n",
    "    - allows you to render Jupyter notebooks as a Reveal.js-based slideshow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Which of the following do you use on everyday basis?\n",
    "\n",
    "- Hover over the area above screen sharing to see the toolbar/options and click on \"Annotate\".  \n",
    "- Select \"Stamp\" and put your favourite stamps in the appropriate box(s). \n",
    "\n",
    "<center>\n",
    "<img src=\"images/annotation-exercise.png\" height=\"1400\" width=\"1400\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A common component in all these services is **a language model**!! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is a language model? \n",
    "\n",
    "A model that computes the probability of a sequence of words or the probability of an upcoming word is called a **language model**.\n",
    "\n",
    "- Compute the probability of a sentence or a sequence of words.\n",
    "    - $P(w_1, w_2,\\dots,w_t)$\n",
    "    - P(I have read this book) > P(eye have red this book)\n",
    "\n",
    "- A related task: What's the probability of an upcoming word? \n",
    "    - $P(w_t|w_1,w_2,\\dots,w_{t-1})$ \n",
    "    - P(book | I have read this) > P(book | Eye have red this)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Language modeling: Why should we care?\n",
    "\n",
    "Powerful idea in NLP and helps in many tasks.\n",
    "- Machine translation \n",
    "    * P(In the age of data algorithms have the answer) > P(the age data of in algorithms answer the have)\n",
    "- Spelling correction\n",
    "    * My office is a 20  <span style=\"color:red\">minuet</span> bike ride from my home.  \n",
    "        * P(20 <span style=\"color:blue\">minute</span> bike ride from my home) > P(20 <span style=\"color:red\">minuet</span> bike ride from my home)\n",
    "- Speech recognition \n",
    "    * P(<span style=\"color:blue\">I read</span> a book) > P(<span style=\"color:red\">Eye red</span> a book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Language model examples "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 1: Voice assistants\n",
    "\n",
    "\n",
    "<center>\n",
    "<img src=\"images/voice-assistant-ex.png\" height=\"1400\" width=\"1400\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kvarada/opt/miniconda3/lib/python3.7/site-packages/IPython/core/display.py:701: UserWarning: Consider using IPython.display.IFrame instead\n",
      "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe src=https://ai.googleblog.com/2018/05/smart-compose-using-neural-networks-to.html width=1000 height=900 allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example 2: Gmail smart compose\n",
    "url = \"https://ai.googleblog.com/2018/05/smart-compose-using-neural-networks-to.html\"\n",
    "display_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=https://www.youtube.com/embed/fZSFNUT6iY8?rel=0&amp;controls=0&amp;showinfo=0 width=2000 height=900 allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Example 3: Code generation using the most recent language model GPT-3\n",
    "url = \"https://www.youtube.com/embed/fZSFNUT6iY8?rel=0&amp;controls=0&amp;showinfo=0\"\n",
    "HTML(\"<iframe src=%s width=2000 height=900 allowfullscreen></iframe>\"%url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A naive way to calculate probabilities of a sentence\n",
    "\n",
    "- Calculate probabilities of a sequence by applying chain rule \n",
    "- Example: Suppose we want to calculate the probability of the following sequence of words: \n",
    "\n",
    "$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "P(\\textrm{In the age of data algorithms have the answer}) =& P(\\textrm{In}) \\times P(\\textrm{the|In})\\\\ \n",
    "                                              & \\times P(\\textrm{age|In the}) \\times P(\\textrm{of|In the age})\\\\\n",
    "                                              & \\times P(\\textrm{data|In the age of})\\\\\n",
    "                                              & \\times P(\\textrm{algorithms|In the age of data}) \\\\\n",
    "                                              &  \\times P(\\textrm{have|In the age of data algorithms}) \\\\\n",
    "                                              & \\dots \n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "- <span style=\"color:red\">BAD IDEA!!</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Markov models of language\n",
    "\n",
    "**Markov assumption: The future is conditionally independent of the past given present**\n",
    "<center>\n",
    "<img src=\"images/Markov-assumption.png\" height=\"700\" width=\"700\">\n",
    "</center>\n",
    "\n",
    "- Bigram language model\n",
    "    \n",
    "$$\n",
    "P(\\textrm{algorithms|age of data}) \\approx P(\\textrm{algorithms|data})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Markov model of language (bigram language model)\n",
    "\n",
    "- Use Markov assumption and calculate the probability of a sequence as follows!\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "P(\\textrm{In the age of data algorithms have the answer}) =& P(\\textrm{In}) \\times P(\\textrm{the|In})\\\\ \n",
    "                                              & \\times P(\\textrm{age|the})\\\\\n",
    "                                              & \\times P(\\textrm{of|age})\\\\\n",
    "                                              & \\times P(\\textrm{data|of})\\\\\n",
    "                                              & \\times P(\\textrm{algorithms|data}) \\\\                 \n",
    "                                              & \\times P(\\textrm{have|algorithms}) \\\\                             \n",
    "                                              & \\times P(\\textrm{the|have}) \\\\                                   \n",
    "                                              & \\times P(\\textrm{answer|the}) \\\\                                                                                 \n",
    "\\end{split}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Estimating probabilities for the bigram language model\n",
    "\n",
    "<center>\n",
    "<img src=\"images/bigram-proba.png\" height=\"900\" width=\"900\">\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Text generation using Markov models of languaage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "toy_corpus = '''The birds they sang\n",
    "At the break of day\n",
    "Start again\n",
    "I heard them say\n",
    "Don't dwell on what\n",
    "Has passed away\n",
    "Or what is yet to be\n",
    "Yeah the wars they will\n",
    "Be fought again\n",
    "The holy dove\n",
    "She will be caught again\n",
    "Bought and sold\n",
    "And bought again\n",
    "The dove is never free\n",
    "Ring the bells (ring the bells) that still can ring\n",
    "Forget your perfect offering\n",
    "There is a crack in everything (there is a crack in everything)\n",
    "That's how the light gets in\n",
    "We asked for signs\n",
    "The signs were sent\n",
    "The birth betrayed\n",
    "The marriage spent\n",
    "Yeah the widowhood\n",
    "Of every government\n",
    "Signs for all to see\n",
    "I can't run no more\n",
    "With that lawless crowd\n",
    "While the killers in high places\n",
    "Say their prayers out loud\n",
    "But they've summoned, they've summoned up\n",
    "A thundercloud\n",
    "And they're going to hear from me\n",
    "Ring the bells that still can ring\n",
    "Forget your perfect offering\n",
    "There is a crack, a crack in everything (there is a crack in everything)\n",
    "That's how the light gets in\n",
    "You can add up the parts\n",
    "You won't have the sum\n",
    "You can strike up the march\n",
    "There is no drum\n",
    "Every heart, every heart to love will come\n",
    "But like a refugee\n",
    "Ring the bells that still can ring\n",
    "Forget your perfect offering\n",
    "There is a crack, a crack in everything (there is a crack in everything)\n",
    "That's how the light gets in\n",
    "Ring the bells that still can ring (ring the bells that still can ring)\n",
    "Forget your perfect offering\n",
    "There is a crack, a crack in everything (there is a crack in everything)\n",
    "That's how the light gets in\n",
    "That's how the light gets in\n",
    "That's how the light gets in'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>birds</th>\n",
       "      <th>break</th>\n",
       "      <th>wars</th>\n",
       "      <th>holy</th>\n",
       "      <th>dove</th>\n",
       "      <th>bells</th>\n",
       "      <th>light</th>\n",
       "      <th>signs</th>\n",
       "      <th>birth</th>\n",
       "      <th>marriage</th>\n",
       "      <th>...</th>\n",
       "      <th>out</th>\n",
       "      <th>loud</th>\n",
       "      <th>but</th>\n",
       "      <th>like</th>\n",
       "      <th>summoned</th>\n",
       "      <th>up</th>\n",
       "      <th>going</th>\n",
       "      <th>from</th>\n",
       "      <th>me</th>\n",
       "      <th>wo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>birds</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>they</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sang</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>at</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heart</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>come</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refugee</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         birds  break  wars  holy  dove  bells  light  signs  birth  marriage  \\\n",
       "the        1.0    1.0   1.0   1.0   1.0    6.0    6.0    1.0    1.0       1.0   \n",
       "birds      0.0    0.0   0.0   0.0   0.0    0.0    0.0    0.0    0.0       0.0   \n",
       "they       0.0    0.0   0.0   0.0   0.0    0.0    0.0    0.0    0.0       0.0   \n",
       "sang       0.0    0.0   0.0   0.0   0.0    0.0    0.0    0.0    0.0       0.0   \n",
       "at         0.0    0.0   0.0   0.0   0.0    0.0    0.0    0.0    0.0       0.0   \n",
       "...        ...    ...   ...   ...   ...    ...    ...    ...    ...       ...   \n",
       "heart      0.0    0.0   0.0   0.0   0.0    0.0    0.0    0.0    0.0       0.0   \n",
       "love       0.0    0.0   0.0   0.0   0.0    0.0    0.0    0.0    0.0       0.0   \n",
       "come       0.0    0.0   0.0   0.0   0.0    0.0    0.0    0.0    0.0       0.0   \n",
       "like       0.0    0.0   0.0   0.0   0.0    0.0    0.0    0.0    0.0       0.0   \n",
       "refugee    0.0    0.0   0.0   0.0   0.0    0.0    0.0    0.0    0.0       0.0   \n",
       "\n",
       "         ...  out  loud  but  like  summoned   up  going  from   me   wo  \n",
       "the      ...  0.0   0.0  0.0   0.0       0.0  0.0    0.0   0.0  0.0  0.0  \n",
       "birds    ...  0.0   0.0  0.0   0.0       0.0  0.0    0.0   0.0  0.0  0.0  \n",
       "they     ...  0.0   0.0  0.0   0.0       0.0  0.0    0.0   0.0  0.0  0.0  \n",
       "sang     ...  0.0   0.0  0.0   0.0       0.0  0.0    0.0   0.0  0.0  0.0  \n",
       "at       ...  0.0   0.0  0.0   0.0       0.0  0.0    0.0   0.0  0.0  0.0  \n",
       "...      ...  ...   ...  ...   ...       ...  ...    ...   ...  ...  ...  \n",
       "heart    ...  0.0   0.0  0.0   0.0       0.0  0.0    0.0   0.0  0.0  0.0  \n",
       "love     ...  0.0   0.0  0.0   0.0       0.0  0.0    0.0   0.0  0.0  0.0  \n",
       "come     ...  0.0   0.0  1.0   0.0       0.0  0.0    0.0   0.0  0.0  0.0  \n",
       "like     ...  0.0   0.0  0.0   0.0       0.0  0.0    0.0   0.0  0.0  0.0  \n",
       "refugee  ...  0.0   0.0  0.0   0.0       0.0  0.0    0.0   0.0  0.0  0.0  \n",
       "\n",
       "[115 rows x 115 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_corpus_tokens = nltk.word_tokenize(toy_corpus.lower())\n",
    "\n",
    "frequencies = defaultdict(Counter)\n",
    "for i in range(len(toy_corpus_tokens) - 1):\n",
    "    frequencies[toy_corpus_tokens[i: i + 1][0]][toy_corpus_tokens[i + 1]] += 1\n",
    "    \n",
    "freq_df = pd.DataFrame(frequencies).transpose()\n",
    "freq_df = freq_df.fillna(0)\n",
    "freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>birds</th>\n",
       "      <th>break</th>\n",
       "      <th>wars</th>\n",
       "      <th>holy</th>\n",
       "      <th>dove</th>\n",
       "      <th>bells</th>\n",
       "      <th>light</th>\n",
       "      <th>signs</th>\n",
       "      <th>birth</th>\n",
       "      <th>marriage</th>\n",
       "      <th>...</th>\n",
       "      <th>out</th>\n",
       "      <th>loud</th>\n",
       "      <th>but</th>\n",
       "      <th>like</th>\n",
       "      <th>summoned</th>\n",
       "      <th>up</th>\n",
       "      <th>going</th>\n",
       "      <th>from</th>\n",
       "      <th>me</th>\n",
       "      <th>wo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>birds</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>they</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sang</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>at</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heart</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>come</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refugee</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         birds  break  wars  holy  dove  bells  light  signs  birth  marriage  \\\n",
       "the       0.04   0.04  0.04  0.04  0.04   0.24   0.24   0.04   0.04      0.04   \n",
       "birds     0.00   0.00  0.00  0.00  0.00   0.00   0.00   0.00   0.00      0.00   \n",
       "they      0.00   0.00  0.00  0.00  0.00   0.00   0.00   0.00   0.00      0.00   \n",
       "sang      0.00   0.00  0.00  0.00  0.00   0.00   0.00   0.00   0.00      0.00   \n",
       "at        0.00   0.00  0.00  0.00  0.00   0.00   0.00   0.00   0.00      0.00   \n",
       "...        ...    ...   ...   ...   ...    ...    ...    ...    ...       ...   \n",
       "heart     0.00   0.00  0.00  0.00  0.00   0.00   0.00   0.00   0.00      0.00   \n",
       "love      0.00   0.00  0.00  0.00  0.00   0.00   0.00   0.00   0.00      0.00   \n",
       "come      0.00   0.00  0.00  0.00  0.00   0.00   0.00   0.00   0.00      0.00   \n",
       "like      0.00   0.00  0.00  0.00  0.00   0.00   0.00   0.00   0.00      0.00   \n",
       "refugee   0.00   0.00  0.00  0.00  0.00   0.00   0.00   0.00   0.00      0.00   \n",
       "\n",
       "         ...  out  loud  but  like  summoned   up  going  from   me   wo  \n",
       "the      ...  0.0   0.0  0.0   0.0       0.0  0.0    0.0   0.0  0.0  0.0  \n",
       "birds    ...  0.0   0.0  0.0   0.0       0.0  0.0    0.0   0.0  0.0  0.0  \n",
       "they     ...  0.0   0.0  0.0   0.0       0.0  0.0    0.0   0.0  0.0  0.0  \n",
       "sang     ...  0.0   0.0  0.0   0.0       0.0  0.0    0.0   0.0  0.0  0.0  \n",
       "at       ...  0.0   0.0  0.0   0.0       0.0  0.0    0.0   0.0  0.0  0.0  \n",
       "...      ...  ...   ...  ...   ...       ...  ...    ...   ...  ...  ...  \n",
       "heart    ...  0.0   0.0  0.0   0.0       0.0  0.0    0.0   0.0  0.0  0.0  \n",
       "love     ...  0.0   0.0  0.0   0.0       0.0  0.0    0.0   0.0  0.0  0.0  \n",
       "come     ...  0.0   0.0  1.0   0.0       0.0  0.0    0.0   0.0  0.0  0.0  \n",
       "like     ...  0.0   0.0  0.0   0.0       0.0  0.0    0.0   0.0  0.0  0.0  \n",
       "refugee  ...  0.0   0.0  0.0   0.0       0.0  0.0    0.0   0.0  0.0  0.0  \n",
       "\n",
       "[115 rows x 115 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_df = freq_df.div(freq_df.sum(axis=1), axis=0)\n",
    "trans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE GENERATED SEQUENCE:\n",
      "   the light gets in everything ) that lawless crowd while the light gets in everything ) that still can strike up a crack in ring the bells ( there is a crack , a crack in that lawless crowd while the marriage spent yeah the light gets in everything ( ring the bells that still can ring ) that 's how the bells that 's how the killers in everything ) that lawless crowd while the marriage spent yeah the break of every government signs the killers in you wo n't dwell on what has passed away or what has\n"
     ]
    }
   ],
   "source": [
    "### Generate text using the Markov model above\n",
    "start_word = 'the'\n",
    "seq_len = 100\n",
    "seq = ''\n",
    "word = start_word\n",
    "for i in range(seq_len):    \n",
    "    seq += \" \" + word\n",
    "    next_word = npr.choice(trans_df.columns.tolist(), p = trans_df.loc[word,].values.flatten())\n",
    "    #print('The sampled next character is: ', next_char)\n",
    "    word = next_word\n",
    "print('THE GENERATED SEQUENCE:\\n ', seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### In practice ... \n",
    "\n",
    "- the corpora (datasets) are usually huge and the probabilities make more sense. \n",
    "- Examples\n",
    "    - All emails sent/received using Gmail.  \n",
    "    - Complete Wikipedia.\n",
    "    - The text available on the entire Internet.\n",
    "    - The New York Times articles from the last 20 years. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Considering more history \n",
    "\n",
    "- Example: trigrams or four-gram language model\n",
    "    - Trigram language model\n",
    "$$\n",
    "P(\\textrm{algorithms|In the age of data}) \\approx P(\\textrm{algorithms|of data})\n",
    "$$\n",
    "    - Four-gram language model\n",
    "$$\n",
    "P(\\textrm{algorithms|In the age of data}) \\approx P(\\textrm{algorithms|age of data})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ASIDE: [Google n-gram viewer](https://books.google.com/ngrams)\n",
    " \n",
    "- All Our N-gram are Belong to You\n",
    "    - https://ai.googleblog.com/2006/08/all-our-n-gram-are-belong-toyou.html\n",
    "\n",
    "<blockquote>\n",
    "Here at Google Research we have been using word n-gram models for a variety\n",
    "of R&D projects, such as statistical machine translation, speech recognition,\n",
    "spelling correction, entity detection, information extraction, and others.\n",
    "That's why we decided to share this enormous dataset with everyone. We\n",
    "processed 1,024,908,267,229 words of running text and are publishing the\n",
    "counts for all 1,176,470,663 five-word sequences that appear at least 40\n",
    "times. There are 13,588,391 unique words, after discarding words that appear\n",
    "less than 200 times.”\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kvarada/opt/miniconda3/lib/python3.7/site-packages/IPython/core/display.py:701: UserWarning: Consider using IPython.display.IFrame instead\n",
      "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe src=https://books.google.com/ngrams/ width=1000 height=900 allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = \"https://books.google.com/ngrams/\"\n",
    "display_url(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## More advanced language models \n",
    "\n",
    "- Incorporate more flexible context compared to bigram/trigram/4-gram models \n",
    "- Built using deep neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [GPT-3 language model](https://github.com/openai/gpt-3)\n",
    "\n",
    "- A state-of-the-art language model with 175 billion parameters!!\n",
    "- Task agnostic and works for many different tasks.   \n",
    "- Currently very popular (and overhyped)\n",
    "\n",
    "#### GPT-3 in news\n",
    "- [How Do You Know a Human Wrote This?](https://www.nytimes.com/2020/07/29/opinion/gpt-3-ai-automation.html)\n",
    "- [GPT-3 writes climate change protest letters to Trump, Xi, and Putin](https://thenextweb.com/neural/2020/08/12/gpt-3-writes-climate-change-protest-letters-to-trump-xi-and-putin/)\n",
    "- [Is GPT-3 the big leap forward for AI?](https://www.rte.ie/brainstorm/2020/0811/1158560-gpt3-artificial-intelligence-machine-learning/)\n",
    "- [OpenAI’s new language generator GPT-3 is shockingly good—and completely mindless](https://www.technologyreview.com/2020/07/20/1005454/openai-machine-learning-language-generator-gpt-3-nlp/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Limitations of language models \n",
    "\n",
    "- All these complicated models are based on the simple idea of predicting next word given a sequence of words. \n",
    "- These models do not have common-sense knowledge or the ability to reason or reflect. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "\n",
    "## Example where the model does reasonably well\n",
    "\n",
    "Q: How many eyes does a giraffe have?<br>\n",
    "A: A giraffe has two eyes.\n",
    "\n",
    "Q: How many legs does a frog have?<br>\n",
    "A: A frog has four legs.\n",
    "\n",
    "Q: Are there any animals with three legs?<br>\n",
    "A: No, there are no animals with three legs.\n",
    "\n",
    "Q: Why don't animals have three legs?<br>\n",
    "A: Animals don't have three legs because they would fall over.\n",
    "\n",
    "[Source](https://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example where the model shows lack of common sense knowledge \n",
    "\n",
    "Q: Which is heavier, a mouse or an elephant?<br> \n",
    "A: An elephant is heavier than a mouse.\n",
    "\n",
    "Q: Which is heavier, a mouse or a toaster?<br>\n",
    "A: A toaster is heavier than a mouse.\n",
    "\n",
    "Q: Which is heavier, a toaster or a pencil?<br>\n",
    "A: A pencil is heavier than a toaster.\n",
    "\n",
    "[Source](https://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Summary\n",
    "\n",
    "- The idea of a language model is to calculate the probability of a word given a sequence of words. \n",
    "- They are powerful and can be used for many tasks but they have their own limitations. \n",
    "- The same idea can be used to generate sequences beyond language. \n",
    "- Here is an example of generating music by predicting notes given a sequence of notes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=https://magenta.tensorflow.org/performance-rnn width=1000 height=900 allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = \"https://magenta.tensorflow.org/performance-rnn\"\n",
    "display_url(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Resources \n",
    "\n",
    "- See [this famous blog](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). \n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
